{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import os\n",
    "import cred\n",
    "from oandapyV20.contrib.factories import InstrumentsCandlesFactory\n",
    "import oandapyV20.endpoints.accounts as accounts\n",
    "import oandapyV20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTER_LIST_FAILED_SYMBOLS = []\n",
    "\n",
    "def load_db_credential_info(f_name_path):\n",
    "    \"\"\"\n",
    "    load text file holding our database credential info and the database name\n",
    "    args:\n",
    "        f_name_path: name of file preceded with \"\\\\\", type string\n",
    "    returns:\n",
    "        array of 4 values that should match text file info\n",
    "    \"\"\"\n",
    "    cur_path = os.getcwd()\n",
    "    # lets load our database credentials and info\n",
    "    f = open(cur_path + f_name_path, 'r')\n",
    "    lines = f.readlines()[1:]\n",
    "    lines = lines[0].split(',')\n",
    "    return lines\n",
    "    \n",
    "def obtain_list_db_tickers(conn):\n",
    "    \"\"\"\n",
    "    query our Postgres database table 'symbol' for a list of all tickers in our symbol table\n",
    "    args:\n",
    "        conn: a Postgres DB connection object\n",
    "    returns: \n",
    "        list of tuples\n",
    "    \"\"\"\n",
    "    with conn:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT id, ticker FROM symbol\")\n",
    "        data = cur.fetchall()\n",
    "        return [(d[0], d[1]) for d in data]\n",
    "\n",
    "def fetch_vendor_id(vendor_name, conn):\n",
    "    \"\"\"\n",
    "    Retrieve our vendor id from our PostgreSQL DB, table data_vendor.\n",
    "    args:\n",
    "        vendor_name: name of our vendor, type string.\n",
    "        conn: a Postgres DB connection object\n",
    "    return:\n",
    "        vendor id as integer\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT id FROM data_vendor WHERE name = %s\", (vendor_name,))\n",
    "    # will return a list of tuples\n",
    "    vendor_id = cur.fetchall()\n",
    "    # index to our first tuple and our first value\n",
    "    vendor_id = vendor_id[0][0]\n",
    "    return vendor_id\n",
    "\n",
    "\n",
    "def load_data(symbol, symbol_id, vendor_id, conn, start_date):\n",
    "    \"\"\"\n",
    "    This will load stock data (date+OHLCV) and additional info to our daily_data table.\n",
    "    args:\n",
    "        symbol: stock ticker, type string.\n",
    "        symbol_id: stock id referenced in symbol(id) column, type integer.\n",
    "        vendor_id: data vendor id referenced in data_vendor(id) column, type integer.\n",
    "        conn: a Postgres DB connection object\n",
    "    return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    accountID=cred.acc_id_prac\n",
    "    access_token=cred.token_prac\n",
    "    api = oandapyV20.API(access_token=access_token)\n",
    "    client = oandapyV20.API(access_token=access_token)\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    end_dt = datetime.datetime.now()\n",
    "    \n",
    "    print(\"NAARI\",start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"))\n",
    "    try:\n",
    "        data = oanda_historical_data(instrument=symbol,start_date=start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),end_date=end_dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),client=client)\n",
    "        # data = yf.download(symbol, start=start_dt, end=end_dt)\n",
    "    except:\n",
    "        print(\"PODA\",symbol)\n",
    "        MASTER_LIST_FAILED_SYMBOLS.append(symbol)\n",
    "#         print(\"ENTHADA\",MASTER_LIST_FAILED_SYMBOLS)\n",
    "        raise Exception('Failed to load {}'.format(symbol))\n",
    "        \n",
    "    if ~ data.empty:        \n",
    "        # create new dataframe matching our table schema\n",
    "        # and re-arrange our dataframe to match our database table\n",
    "        columns_table_order = ['data_vendor_id', 'stock_id', 'created_date', \n",
    "                               'last_updated_date', 'date_price', 'open_price',\n",
    "                               'high_price', 'low_price', 'close_price', 'volume']\n",
    "        newDF = pd.DataFrame()\n",
    "        newDF['date_price'] =  data.index\n",
    "        data.reset_index(drop=True,inplace=True)\n",
    "        newDF['open_price'] = data['open']\n",
    "        newDF['high_price'] = data['high']\n",
    "        newDF['low_price'] = data['low']\n",
    "        newDF['close_price'] = data['close']\n",
    "        newDF['volume'] = data['volume']\n",
    "        newDF['stock_id'] = symbol_id\n",
    "        newDF['data_vendor_id'] = vendor_id\n",
    "        newDF['created_date'] = datetime.datetime.utcnow()\n",
    "        newDF['last_updated_date'] = datetime.datetime.utcnow()\n",
    "        newDF = newDF[columns_table_order]\n",
    "\n",
    "\n",
    "        # ensure our data is sorted by date\n",
    "        newDF = newDF.sort_values(by=['date_price'], ascending = True)\n",
    "\n",
    "        print(newDF['stock_id'].unique())\n",
    "        print(newDF['date_price'].min())\n",
    "        print(newDF['date_price'].max())\n",
    "        print(\"\")\n",
    "\n",
    "        # convert our dataframe to a list\n",
    "        list_of_lists = newDF.values.tolist()\n",
    "        # convert our list to a list of tuples       \n",
    "        tuples_mkt_data = [tuple(x) for x in list_of_lists]\n",
    "\n",
    "        # WRITE DATA TO DB\n",
    "        insert_query =  \"\"\"\n",
    "                        INSERT INTO daily_data (data_vendor_id, stock_id, created_date,\n",
    "                        last_updated_date, date_price, open_price, high_price, low_price, close_price, volume) \n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                        \"\"\"\n",
    "        cur.executemany(insert_query, tuples_mkt_data)\n",
    "        conn.commit()    \n",
    "        print('{} complete!'.format(symbol))\n",
    "\n",
    "\n",
    "def oanda_historical_data(instrument,start_date,end_date,granularity='D',client=None):\n",
    "    params = {\n",
    "    \"from\": start_date,\n",
    "    \"to\": end_date,\n",
    "    \"granularity\": granularity,\n",
    "    \"count\": 2500,\n",
    "    }\n",
    "\n",
    "    df_full=pd.DataFrame()\n",
    "    for r in InstrumentsCandlesFactory(instrument=instrument,params=params):\n",
    "#         print(\"PODA....\",instrument)\n",
    "        client.request(r)\n",
    "        dat = []\n",
    "        api_data=r.response.get('candles')\n",
    "        if(api_data):\n",
    "            for oo in r.response.get('candles'):\n",
    "                dat.append([oo['time'], oo['volume'], oo['mid']['o'], oo['mid']['h'], oo['mid']['l'], oo['mid']['c']])\n",
    "\n",
    "            df = pd.DataFrame(dat)\n",
    "            df.columns = ['time', 'volume', 'open', 'high', 'low', 'close']\n",
    "            df = df.set_index('time')\n",
    "            if df_full.empty:\n",
    "                df_full=df\n",
    "            else:\n",
    "                df_full=df_full.append(df)\n",
    "    df_full.index=pd.to_datetime(df_full.index)    \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/SecMaster/interested_tickers.xlsx\n"
     ]
    }
   ],
   "source": [
    "ticker_info_file = \"/interested_tickers.xlsx\"\n",
    "ticker_info_file_p =  ticker_info_file\n",
    "cur_path = os.getcwd()\n",
    "f = cur_path + ticker_info_file_p\n",
    "print(f)\n",
    "df_tickers=pd.read_excel(f,sheet_name='daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>EUR_USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tickers\n",
       "0  EUR_USD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   last_date  stock_id   ticker\n",
      "0 2010-12-31        17  EUR_USD\n",
      "1 2010-12-31        58  GBP_USD\n"
     ]
    }
   ],
   "source": [
    "db_info_file = \"database_info.txt\"\n",
    "db_info_file_p = \"/\" + db_info_file\n",
    "# necessary database info to connect\n",
    "db_host, db_user, db_password, db_name = load_db_credential_info(db_info_file_p)\n",
    "\n",
    "# connect to our securities_master database\n",
    "conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)\n",
    "\n",
    "# vendor name for Yahoo\n",
    "vendor = 'Oanda'\n",
    "vendor_id = fetch_vendor_id(vendor, conn)\n",
    "\n",
    "df_tickers=pd.read_excel(\"interested_tickers.xlsx\",sheet_name='minute')\n",
    "\n",
    "if not df_tickers.empty:\n",
    "#     print(\"Empty Ticker List\")\n",
    "    sql=\"\"\"select a.last_date, b.id as stock_id, b.ticker from\n",
    "    (select max(date_price) as last_date, stock_id\n",
    "    from daily_data \n",
    "    group by stock_id) a right join symbol b on a.stock_id = b.id \n",
    "    where b.ticker in {}\"\"\".format(tuple(df_tickers['Tickers'])).replace(\",)\", \")\")\n",
    "    df_ticker_last_day=pd.read_sql(sql,con=conn)\n",
    "\n",
    "    # Filling the empty dates returned from the DB\n",
    "    df_ticker_last_day['last_date'].fillna(datetime.datetime(2010,12,30),inplace=True)\n",
    "\n",
    "    # Adding 1 day, so that the data is appended starting next date\n",
    "    df_ticker_last_day['last_date']=df_ticker_last_day['last_date']+datetime.timedelta(days=1)\n",
    "\n",
    "    # # If there's no data for the ticker, then it will download the data from 2010 onwards\n",
    "    # if(df_ticker_last_day.empty):\n",
    "    #     sql=\"\"\"select id as stock_id, ticker from symbol where ticker in {}\"\"\".format(tuple(df_tickers['Tickers'])).replace(\",)\", \")\")\n",
    "    #     df_ticker_last_day=pd.read_sql(sql,con=conn)\n",
    "    #     df_ticker_last_day['last_date']=datetime.datetime(2010,12,30)\n",
    "\n",
    "    print(df_ticker_last_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_date</th>\n",
       "      <th>stock_id</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2010-12-30 00:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>EUR_USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-04 21:00:00</td>\n",
       "      <td>58</td>\n",
       "      <td>GBP_USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            last_date  stock_id   ticker\n",
       "0 2010-12-30 00:00:00        17  EUR_USD\n",
       "1 2019-10-04 21:00:00        58  GBP_USD"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ticker_last_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-12-30 00:00:00\n",
      "2010-12-30 00:01:00\n"
     ]
    }
   ],
   "source": [
    "initial_start_date = datetime.datetime(2010,12,30)\n",
    "print(initial_start_date)\n",
    "print(initial_start_date+datetime.timedelta(minutes=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000007\n",
      "NAARI 2010-12-31T00:00:00Z\n",
      "[17]\n",
      "2010-12-30 22:00:00+00:00\n",
      "2019-10-03 21:00:00+00:00\n",
      "\n",
      "EUR_USD complete!\n",
      "NAARI 2019-10-04T21:00:00Z\n",
      "[]\n",
      "0:00:01.437399\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    initial_start_date = datetime.datetime(2010,12,30)\n",
    "    db_info_file = \"database_info.txt\"\n",
    "    db_info_file_p = \"/\" + db_info_file\n",
    "    # necessary database info to connect\n",
    "    db_host, db_user, db_password, db_name = load_db_credential_info(db_info_file_p)\n",
    "\n",
    "    # connect to our securities_master database\n",
    "    conn = psycopg2.connect(host=db_host, database=db_name, user=db_user, password=db_password)\n",
    "\n",
    "    # vendor name for Yahoo\n",
    "    vendor = 'Oanda'\n",
    "    vendor_id = fetch_vendor_id(vendor, conn)\n",
    "\n",
    "    df_tickers=pd.read_csv(\"interested_tickers.csv\")\n",
    "\n",
    "    sql=\"\"\"select a.last_date, b.id as stock_id, b.ticker from\n",
    "    (select max(date_price) as last_date, stock_id\n",
    "    from daily_data \n",
    "    group by stock_id) a right join symbol b on a.stock_id = b.id \n",
    "    where b.ticker in {}\"\"\".format(tuple(df_tickers['Tickers'])).replace(\",)\", \")\")\n",
    "    df_ticker_last_day=pd.read_sql(sql,con=conn)\n",
    "\n",
    "    # Filling the empty dates returned from the DB with the initial start date\n",
    "    df_ticker_last_day['last_date'].fillna(initial_start_date,inplace=True)\n",
    "\n",
    "    # Adding 1 day, so that the data is appended starting next date\n",
    "    df_ticker_last_day['last_date']=df_ticker_last_day['last_date']+datetime.timedelta(days=1)\n",
    "    \n",
    "    startTime = datetime.datetime.now()\n",
    "\n",
    "    print (datetime.datetime.now() - startTime)\n",
    "\n",
    "    for i,stock in df_ticker_last_day.iterrows() :\n",
    "        # download stock data and dump into daily_data table in our Postgres DB\n",
    "        last_date = stock['last_date']\n",
    "        symbol_id = stock['stock_id']\n",
    "        symbol = stock['ticker']\n",
    "        try:\n",
    "            load_data(symbol, symbol_id, vendor_id, conn, start_date=last_date)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # lets write our failed stock list to text file for reference\n",
    "    file_to_write = open('failed_symbols.txt', 'w')\n",
    "    print(MASTER_LIST_FAILED_SYMBOLS)\n",
    "    for symbol in MASTER_LIST_FAILED_SYMBOLS:\n",
    "        file_to_write.write(\"%s\\n\" % symbol)\n",
    "\n",
    "    print(datetime.datetime.now() - startTime)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
